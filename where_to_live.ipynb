{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from csv import DictReader\n",
    "import googlemaps\n",
    "import datetime\n",
    "import json\n",
    "import io\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.error import HTTPError\n",
    "import numpy as np\n",
    "import os\n",
    "import hashlib\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [40, 20]\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATIONS = ['Zurich HB', 'Zurich Hardbruecke']\n",
    "YEAR_OF_BIRTH = 1986\n",
    "FRANCHISE = 2500\n",
    "BASE_TAX = 5000\n",
    "WORK_DAYS_PER_YEAR = 195\n",
    "HOURLY_SALARY = 47\n",
    "MAX_COMMUTE_MINS = 30\n",
    "MONEY_PENALTY_PER_ADDITIONAL_MINUTE = 1.5\n",
    "MAX_NUM_VEHICLES = 1\n",
    "MONEY_PENALTY_PER_ADDITIONAL_VEHICLE = 10\n",
    "MIN_ROOMS = 4.5\n",
    "MAX_ROOMS = 5.5\n",
    "rooms = \"{}-{}\".format(MIN_ROOMS, MAX_ROOMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directions_data(origin, destination):\n",
    "    gmaps = googlemaps.Client('AIzaSyCOUfc_MImzwE4Zu4pnANIPkVk-EzRZgQw')\n",
    "    departure_time = datetime.datetime.now().replace(hour=8, minute=0, second=0, microsecond=0)\n",
    "    try:\n",
    "        directions_results = gmaps.directions(origin=origin, destination=destination, mode='transit', departure_time=departure_time)\n",
    "        leg = directions_results[0]['legs'][0]\n",
    "        return leg\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_time_in_vehicle(leg):\n",
    "    relevant_steps = filter(lambda x: x['travel_mode'] == 'TRANSIT', leg['steps'])\n",
    "    durations = map(lambda x: x['duration']['value'], relevant_steps)\n",
    "    return sum(durations)\n",
    "\n",
    "def get_number_of_vehicles(leg):\n",
    "    relevant_steps = filter(lambda x: x['travel_mode'] == 'TRANSIT', leg['steps'])\n",
    "    return len(list(relevant_steps))\n",
    "\n",
    "def get_distance_to_first_station(leg):\n",
    "    pass\n",
    "\n",
    "def expand_town_name(town_name):\n",
    "    town_name = town_name.replace('a.A.', 'am Albis')\n",
    "    town_name = town_name.replace('a.S.', 'am See')\n",
    "    town_name = town_name.replace('a.d.L.', 'an der Limmat')\n",
    "    town_name = town_name.replace('a.d.Th.', 'an der Thur')\n",
    "    town_name = town_name.replace('a.I.', 'am Irchel')\n",
    "    return town_name\n",
    "\n",
    "def get_umlaut_dict():\n",
    "    return {\n",
    "        'Ä': 'Ae',\n",
    "        'Ö': 'Oe',\n",
    "        'Ü': 'Ue',\n",
    "        'ä': 'ae',\n",
    "        'ö': 'oe',\n",
    "        'ü': 'ue'\n",
    "    }\n",
    "\n",
    "def get_rent_info(zip_codes):\n",
    "    rents = dict()\n",
    "    for zip_code in zip_codes:\n",
    "        homegate = 'https://www.homegate.ch/rent/real-estate/zip-{}/matching-list?ac={}&ad={}'.format(zip_code, MIN_ROOMS, MAX_ROOMS)\n",
    "        response = urllib.request.urlopen(homegate).read()\n",
    "        soup = BeautifulSoup(response)\n",
    "        articles = soup.findAll('article', class_='box-row-wrapper')\n",
    "        if len(articles) > 0:\n",
    "            keys = map(lambda x: hashlib.sha224(bytes(x.text, encoding='utf-8')).hexdigest(), articles)\n",
    "            divs = map(lambda x: x.findAll('div', class_='item-content-label')[0], articles)\n",
    "            spans = map(lambda x: x.findAll('span')[0], divs)\n",
    "            texts = map(lambda x: x.text.strip('\\n'), spans)\n",
    "            clean_texts = map(lambda x: x.replace('.', '').replace(' ', '').replace('–', '').replace(',', ''), texts)\n",
    "            clean_texts_by_keys = zip(keys, clean_texts)\n",
    "            numbers = filter(lambda x: x[1].isdigit(), clean_texts_by_keys)\n",
    "            ints_by_keys = map(lambda x: (x[0], int(x[1])), numbers)\n",
    "            rents_by_keys = dict(ints_by_keys)\n",
    "            rents.update(rents_by_keys)\n",
    "    return rents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract town names and zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "town_info = json.load(open('town_info.json', 'r'))\n",
    "raw_files = ['zh_raw.csv']\n",
    "for file in raw_files:\n",
    "    canton = file.split('_')[0].upper()\n",
    "    lines = open('raw_files/' + file, 'r').readlines()\n",
    "    for line in lines:\n",
    "        plz, town_name = line.split(',')\n",
    "        town_name = '{}, {}'.format(town_name.strip(), canton)\n",
    "        if '-' in plz:\n",
    "            start, stop = plz.split('-')\n",
    "            plz = list(range(int(start), int(stop) + 1))\n",
    "        else:\n",
    "            plz = [plz]\n",
    "        if town_name in town_info:\n",
    "            town_info[town_name]['ZipCodes'].extend(plz)\n",
    "            town_info[town_name]['ZipCodes'] = list(set(town_info[town_name]['ZipCodes']))\n",
    "        else:\n",
    "            town_info[town_name] = dict()\n",
    "            town_info[town_name]['ZipCodes'] = plz\n",
    "\n",
    "json.dump(town_info, io.open('town_info.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract commute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "town_info = json.load(open('town_info.json', 'r'))\n",
    "empty_responses = []\n",
    "for origin in town_info:\n",
    "    town_info[origin]['CommuteData'] = dict()\n",
    "    for destination in DESTINATIONS:\n",
    "        leg = get_directions_data(origin, destination)\n",
    "        if leg is None:\n",
    "            empty_responses.append({'Origin': origin, 'Destination': destination})\n",
    "            continue\n",
    "        town_info[origin]['CommuteData'][destination] = {\n",
    "            'Destination': destination,\n",
    "            'TotalSeconds': leg['duration']['value'],\n",
    "            'TotalMinutes': leg['duration']['value']/60,\n",
    "            'SecondsInVehicle': get_time_in_vehicle(leg),\n",
    "            'MinutesInVehicle': get_time_in_vehicle(leg)/60,\n",
    "            'NumberOfVehicles': get_number_of_vehicles(leg)\n",
    "        }\n",
    "\n",
    "json.dump(town_info, io.open('town_info.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)\n",
    "json.dump(empty_responses, io.open('empty_responses.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract tax rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "town_info = json.load(open('town_info.json', 'r'))\n",
    "unmatched_town_names = []\n",
    "town_name_mappings = {\n",
    "    'Adlikon': ['Adlikon bei Regensdorf'],\n",
    "    'Aesch': ['Aesch bei Birmensdorf'],\n",
    "    'Egg': ['Egg bei Zürich'],\n",
    "    'Illnau-Effretikon' : ['Illnau', 'Effretikon'],\n",
    "    'Freienstein-Teufen': ['Freienstein', 'Teufen'],\n",
    "    'Laufen-Uhwiesen': ['Uhwiesen'],\n",
    "    'Schlatt': ['Schlatt bei Winterthur'],\n",
    "    'Seegräben': ['Aathal-Seegräben'],\n",
    "    'Stadel' : ['Stadel bei Niederglatt'],\n",
    "    'Uitikon': ['Uitikon Waldegg'],\n",
    "    'Wangen-Brüttisellen': ['Brüttisellen'],\n",
    "    'Wettswil am Albis': ['Wettswil']\n",
    "}\n",
    "with open('tax_rates.csv', 'r') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        town_name = line.split(',')[0].strip('\"\"')\n",
    "        town_name = expand_town_name(town_name)\n",
    "        if town_name in town_name_mappings:\n",
    "            town_names = town_name_mappings[town_name]\n",
    "        else:\n",
    "            town_names = [town_name]\n",
    "        for town_name in town_names:\n",
    "            town_name = town_name + ', ZH'\n",
    "            tax_rate = int(line.split(',')[1].strip('\"\"'))\n",
    "            try:\n",
    "                town_info[town_name]['TaxRate'] = tax_rate\n",
    "            except:\n",
    "                unmatched_town_names.append(town_name)\n",
    "json.dump(town_info, io.open('town_info.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)\n",
    "json.dump(unmatched_town_names, io.open('unmatched_town_names_tax.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract rents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rent offers: 4876\n"
     ]
    }
   ],
   "source": [
    "town_info = json.load(open('town_info.json', 'r'))\n",
    "unmatched_town_names = []\n",
    "for town_name in town_info:\n",
    "    rents = []\n",
    "    zip_codes = town_info[town_name]['ZipCodes']\n",
    "    rents = get_rent_info(zip_codes)\n",
    "    \n",
    "    if len(rents) > 0:\n",
    "        if 'Rents' not in town_info[town_name]:\n",
    "            town_info[town_name]['Rents'] = dict()\n",
    "        if rooms not in town_info[town_name]['Rents']:\n",
    "            town_info[town_name]['Rents'][rooms] = dict()\n",
    "        town_info[town_name]['Rents'][rooms].update(rents)\n",
    "\n",
    "        if 'AvgRent' not in town_info[town_name]:\n",
    "            town_info[town_name]['AvgRent'] = dict()\n",
    "        town_info[town_name]['AvgRent'][rooms] = np.mean(list(town_info[town_name]['Rents'][rooms].values()))\n",
    "        \n",
    "        if 'MedianRent' not in town_info[town_name]:\n",
    "            town_info[town_name]['MedianRent'] = dict()\n",
    "        town_info[town_name]['MedianRent'][rooms] = np.median(list(town_info[town_name]['Rents'][rooms].values()))\n",
    "\n",
    "towns_with_rents = filter(lambda x: rooms in town_info[x]['Rents'], town_info.keys())\n",
    "num_offers_per_town = map(lambda x: len(town_info[x]['Rents'][rooms]), towns_with_rents)\n",
    "print('Total number of rent offers: {}'.format(sum(num_offers_per_town)))\n",
    "\n",
    "json.dump(town_info, io.open('town_info.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)\n",
    "json.dump(unmatched_town_names, io.open('unmatched_town_names_rent.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract insurance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract Insurance Data\n",
    "location_ids = json.load(open('location_ids.json', 'r', encoding='utf-8'))\n",
    "unmatched_zip_codes = []\n",
    "town_info = json.load(open('town_info.json', 'r'))\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'}\n",
    "\n",
    "for town_name in town_info:\n",
    "    zip_code = town_info[town_name]['ZipCodes'][0]\n",
    "    try:\n",
    "        location_id = location_ids['index'][str(zip_code)][0]\n",
    "    except KeyError:\n",
    "        unmatched_zip_codes.append(zip_code)\n",
    "    url = 'https://www.priminfo.admin.ch/de/praemien?location_id={}&yob%5B0%5D={}&franchise%5B0%5D={}&coverage%5B0%5D=1&models%5B%5D=base&display=savings'.format(location_id, YEAR_OF_BIRTH, FRANCHISE)\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    response = urllib.request.urlopen(request).read()\n",
    "    soup = BeautifulSoup(response)\n",
    "    divs = soup.findAll('div', class_='prim-numcell')\n",
    "    texts = map(lambda x: x.text, divs)\n",
    "    relevant_texts = filter(lambda x: 'Monat' in x, texts)\n",
    "    numbers = map(lambda x: x.split('\\n')[-2], relevant_texts)\n",
    "    relevant_numbers = filter(lambda x: x != '—', numbers)\n",
    "    rates = list(map(lambda x: float(x), relevant_numbers))\n",
    "    if 'InsuranceRates' not in town_info[town_name]:\n",
    "        town_info[town_name]['InsuranceRates'] = dict()\n",
    "    if 'AvgInsuranceRate' not in town_info[town_name]:\n",
    "        town_info[town_name]['AvgInsuranceRate'] = dict()\n",
    "    if 'MedianInsuranceRate' not in town_info[town_name]:\n",
    "        town_info[town_name]['MedianInsuranceRate'] = dict()\n",
    "    town_info[town_name]['InsuranceRates'][YEAR_OF_BIRTH] = rates\n",
    "    town_info[town_name]['AvgInsuranceRate'][YEAR_OF_BIRTH] = np.mean(rates)\n",
    "    town_info[town_name]['MedianInsuranceRate'][YEAR_OF_BIRTH] = np.median(rates)\n",
    "    time.sleep(2)\n",
    "    \n",
    "json.dump(town_info, io.open('town_info.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)\n",
    "json.dump(unmatched_zip_codes, io.open('unmatched_zip_codes.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Aggregations and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute yearly cost of living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "town_info = json.load(open('town_info.json', 'r'))\n",
    "for town_name in town_info:\n",
    "    if ('MedianInsuranceRate' in town_info[town_name] \n",
    "        and str(YEAR_OF_BIRTH) in town_info[town_name]['MedianInsuranceRate']\n",
    "        and 'TaxRate' in town_info[town_name]\n",
    "        and 'MedianRent' in town_info[town_name] \n",
    "        and rooms in town_info[town_name]['MedianRent']):\n",
    "\n",
    "        insurance = town_info[town_name]['MedianInsuranceRate'][str(YEAR_OF_BIRTH)]*12\n",
    "        tax = BASE_TAX*town_info[town_name]['TaxRate']/100\n",
    "        rent = town_info[town_name]['MedianRent'][rooms]*12\n",
    "        town_info[town_name]['TotalYearlyCostOfLiving'] = insurance + tax + rent\n",
    "        town_info[town_name]['TotalYearlyCostOfRent'] = rent\n",
    "        town_info[town_name]['TotalYearlyCostOfInsurance'] = insurance\n",
    "        town_info[town_name]['TotalYearlyCostOfTax'] = tax\n",
    "\n",
    "json.dump(town_info, io.open('town_info.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute yearly cost of commute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "town_info = json.load(open('town_info.json', 'r'))\n",
    "max_allowed_commute = MAX_COMMUTE_MINS*WORK_DAYS_PER_YEAR*2/60\n",
    "for town_name in town_info:\n",
    "    if 'CommuteData' in town_info[town_name]:\n",
    "        commute_times = []\n",
    "        for destination in town_info[town_name]['CommuteData']:\n",
    "            commute_times.append((town_info[town_name]['CommuteData'][destination]['TotalMinutes'],\n",
    "                                  town_info[town_name]['CommuteData'][destination]['NumberOfVehicles']))\n",
    "        if len(commute_times) > 0:\n",
    "            preferred_commute = min(commute_times, key=lambda x: x[0])\n",
    "            total_commute = preferred_commute[0]*WORK_DAYS_PER_YEAR*2/60\n",
    "            town_info[town_name]['HoursCommutePerYear'] = total_commute\n",
    "            town_info[town_name]['TotalYearlyCostOfCommute'] = total_commute*HOURLY_SALARY\n",
    "\n",
    "            difference_hours = town_info[town_name]['HoursCommutePerYear'] - max_allowed_commute\n",
    "            if difference_hours > 0:\n",
    "                penalty = difference_hours*60*MONEY_PENALTY_PER_ADDITIONAL_MINUTE\n",
    "                town_info[town_name]['CommuteDelayPenalty'] = penalty\n",
    "            else:\n",
    "                town_info[town_name]['CommuteDelayPenalty'] = 0\n",
    "\n",
    "            difference_vehicles = preferred_commute[1] - MAX_NUM_VEHICLES\n",
    "            if difference_vehicles > 0:\n",
    "                penalty = difference_vehicles*MONEY_PENALTY_PER_ADDITIONAL_VEHICLE*WORK_DAYS_PER_YEAR\n",
    "                town_info[town_name]['CommuteVehiclePenalty'] = penalty\n",
    "            else:\n",
    "                town_info[town_name]['CommuteVehiclePenalty'] = 0\n",
    "        \n",
    "json.dump(town_info, io.open('town_info.json', 'w', encoding='utf-8'), indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show me where da money is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "town_info = json.load(open('town_info.json', 'r'))\n",
    "keys = town_info.keys()\n",
    "relevant_towns = list(filter(\n",
    "    lambda x: 'TotalYearlyCostOfLiving' in town_info[x] \n",
    "    and 'TotalYearlyCostOfCommute', keys))\n",
    "\n",
    "rent = list(map(lambda x: town_info[x]['TotalYearlyCostOfRent'], relevant_towns))\n",
    "insurance = list(map(lambda x: town_info[x]['TotalYearlyCostOfInsurance'], relevant_towns))\n",
    "tax = list(map(lambda x: town_info[x]['TotalYearlyCostOfTax'], relevant_towns))\n",
    "commute_duration = list(map(lambda x: town_info[x]['TotalYearlyCostOfCommute'], relevant_towns))\n",
    "delay_penalties = list(map(lambda x: town_info[x]['CommuteDelayPenalty'], relevant_towns))\n",
    "vehicle_penalties = list(map(lambda x: town_info[x]['CommuteVehiclePenalty'], relevant_towns))\n",
    "\n",
    "all_data = zip(rent,\n",
    "               insurance,\n",
    "               tax,\n",
    "               commute_duration,\n",
    "               delay_penalties,\n",
    "               vehicle_penalties,\n",
    "               relevant_towns)\n",
    "\n",
    "total_cost = list(map(lambda x: (sum(x[0:6]), x), all_data))\n",
    "sorted_data = sorted(total_cost, key=lambda x: x[0])\n",
    "\n",
    "rent = list(map(lambda x: x[1][0], sorted_data))\n",
    "insurance = list(map(lambda x: x[1][1], sorted_data))\n",
    "tax = list(map(lambda x: x[1][2], sorted_data))\n",
    "commute_duration = list(map(lambda x: x[1][3], sorted_data))\n",
    "delay_penalties = list(map(lambda x: x[1][4], sorted_data))\n",
    "vehicle_penalties = list(map(lambda x: x[1][5], sorted_data))\n",
    "relevant_towns = list(map(lambda x: x[1][6], sorted_data))\n",
    "\n",
    "width = 0.9\n",
    "align = 'center'\n",
    "\n",
    "bar_positions = list(range(0, len(relevant_towns), 1))\n",
    "\n",
    "plt.bar(bar_positions, rent, width=width, align=align)\n",
    "cost_up_to_now = rent\n",
    "\n",
    "plt.bar(bar_positions, insurance, bottom=cost_up_to_now, width=width, align=align)\n",
    "cost_up_to_now = list(map(lambda x: sum(x), zip(rent, insurance)))\n",
    "\n",
    "plt.bar(bar_positions, tax, bottom=cost_up_to_now, width=width, align=align)\n",
    "cost_up_to_now = list(map(lambda x: sum(x), zip(cost_up_to_now, tax)))\n",
    "\n",
    "plt.bar(bar_positions, commute_duration, bottom=cost_up_to_now, width=width, align=align)\n",
    "cost_up_to_now = list(map(lambda x: sum(x), zip(cost_up_to_now, commute_duration)))\n",
    "\n",
    "plt.bar(bar_positions, delay_penalties, bottom=cost_up_to_now, width=width, align=align)\n",
    "cost_up_to_now = list(map(lambda x: sum(x), zip(cost_up_to_now, delay_penalties)))\n",
    "\n",
    "plt.bar(bar_positions, vehicle_penalties, bottom=cost_up_to_now, width=width, align=align)\n",
    "cost_up_to_now = list(map(lambda x: sum(x), zip(cost_up_to_now, vehicle_penalties)))\n",
    "\n",
    "plt.xticks(bar_positions, relevant_towns, rotation=90, fontsize=10)\n",
    "plt.legend(('Rent', 'Insurance', 'Tax', 'Commute Duration', 'Commute Delay', 'Number of Vehicles'))\n",
    "plt.show()\n",
    "\n",
    "perfect_town = min(total_cost, key=lambda x: x[0])\n",
    "print('The optimal town to live in is {} at a yearly price of {}!\\n'.format(perfect_town[1][6], int(perfect_town[0])))\n",
    "complete_table = list(map(lambda x: (x[0],) + x[1], sorted_data))\n",
    "complete_table = list(map(lambda x: (x[7], x[0], x[1], x[2], x[3], x[4], x[5], x[6]), complete_table))\n",
    "ranks = range(1, len(complete_table) + 1)\n",
    "complete_table = list(map(lambda x: (x[0],) + x[1], zip(ranks, complete_table)))\n",
    "print(tabulate(complete_table, ('Rank', 'Town', 'Total Cost', 'Rent', 'Insurance', 'Tax','Commute Duration','Delay Penalties','Vehicle Penalties'), tablefmt='grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "where_to_live",
   "language": "python",
   "name": "where_to_live"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
